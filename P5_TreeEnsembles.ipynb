{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktische Übung 5: Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook werden wir verschiedene Formen des \"Ensemble Learning\" einsetzen und einen einfachen Bagging-Algorithmus selbst implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorab initialisieren wir die Zufallsgeneratoren um vergleichbare Ergebnisse zu erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.21.5\n",
      "Sklearn version: 1.1.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Sklearn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für diese Übung verwenden wir den [Wein-Datensatz](https://archive.ics.uci.edu/ml/datasets/wine), welcher ebenfalls ein bekannter Datensatz in der ML-Welt ist.\n",
    "Die offizielle Beschreibung lautet:\n",
    "```\n",
    "These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
    "```\n",
    "Anhand dieser Merkmale soll die Qualität (Spalte `quality`) des Weins vorhergesagt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/wine.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir loslegen, schauen wir uns die Verteilung des Labels an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Decision Tree, Random Forest, GBT\n",
    "Trainieren Sie die folgenden Modelle und ermitteln Sie die Accuarcy auf den Testdaten. Geben Sie dabei jeweils den Parameter `random_state=0` bei der Erstellung des Modells and und beschränken Sie die maximale Baumtiefe auf `max_depth=3`.\n",
    "- Einfacher Entscheidungsbaum (`DecisionTreeClassifier`)\n",
    "- Random Forest (`RandomForestClassifier`)\n",
    "- GBT (`GradientBoostingClassifier`)\n",
    "\n",
    "Hinweis: Für diese Modelle müssen wir die Daten nicht skalieren und kein One-hot-encoding durchführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Einfacher Entscheidungsbaum\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_T = DecisionTreeClassifier(criterion=\"entropy\",random_state=0,max_depth=3)\n",
    "model_T.fit(X_train, y_train)\n",
    "\n",
    "predictions_T = model_T.predict(X_test)\n",
    "\n",
    "print(\"Der Accuracyscore ist\", accuracy_score(y_test, predictions_T)) \n",
    "\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_F = RandomForestClassifier(random_state=0, max_depth=3)\n",
    "model_F.fit(X_train, y_train)\n",
    "\n",
    "predictions_F = model_F.predict(X_test)\n",
    "\n",
    "acc_F = accuracy_score(y_test, predictions_F)\n",
    "\n",
    "print(\"Der Accuracyscore vom Random Forest ist:\", acc_F)\n",
    "\n",
    "#Gradient Boosting Tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_G = GradientBoostingClassifier(random_state=0, max_depth=3)\n",
    "model_G.fit(X_train, y_train)\n",
    "\n",
    "predictions_G = model_G.predict(X_test)\n",
    "acc_G = accuracy_score(y_test, predictions_G)\n",
    "\n",
    "print(\"Der Accuracyscore vom GBT ist:\", acc_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: GBT Tuning\n",
    "Der `GradientBoostingClassifier` und der `RandomForest` haben als Hyperparameter u.a. die Anzahl der Bäume die trainiert werden (`n_estimators`) und die maximale Baumtiefe (`max_depth`), siehe [hier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).\n",
    "\n",
    "- Führen Sie für beide Modelle ein Cross-Validierung über diese Hyperparameter durch, betrachten Sie dabei folgende Werte:  $n\\_estimators \\in [60, 80, 100, 120, 140]$ und $max\\_depth \\in [2, 3, 4, 5]$. Nehmen Sie das Notebook `6_TreeEnsembles` auf unserem GitHub als Vorlage. Hinweis: Sie können alle Hyperparameter auf einmal übergeben. Mehr Details finden Sie wenn Sie [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) bis nach unten zum Code-Beispiel scrollen.\n",
    "- Welches sind die besten Parameter für `max_depth` und `n_estimators` und welches ist das bessere Modell?\n",
    "- Trainieren Sie das bessere Modelle mit den besten Parametern und machen Sie eine Vorhersage auf den Testdaten. Vergleichen Sie die Ergebnisse mit Aufgabe 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_candidates = [{'max_depth':[2, 3, 4, 5],\n",
    "                       'n_estimators':[60, 80, 100, 120, 140]}]\n",
    "\n",
    "gbt = GradientBoostingClassifier(random_state=0)\n",
    "grid_clf = GridSearchCV(estimator=gbt, param_grid=parameter_candidates, n_jobs=-1)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best max_depth:\",grid_clf.best_estimator_.max_depth)\n",
    "print(\"Best n_estimators\", grid_clf.estimator.n_estimators_)\n",
    "print(\"Best score:\", grid_clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#besseres Modell mit besten Parametern\n",
    "model = GradientBoostingClassifier(random_state=0, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracyscore mit besten Parametern:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Bagging-Modell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementieren Sie ein Bagging-Modell von Hand (d.h. nicht die Sklearn-Library verwenden) und testen Sie es auf den Testdaten. Das Bagging-Modell soll folgende Eigenschaften haben:\n",
    "- Das Modell soll 10 Basismodelle haben, welche einfache `DecisionTreeClassifier` sind.\n",
    "- Jeder dieser DecisionTrees soll auf 70% der Trainingsdaten trainiert werden (Sampling mit Zurücklegen). Tipp: Nutzen Sie `X_train.sample(...)`.\n",
    "- Bei der Vorhersage soll die am häufigsten vorhergesagte Klasse als Gesamtvorhersage dienen.\n",
    "- Testen Sie das Modell auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample\n",
    "\n",
    "models = []\n",
    "for i in range(0,9):\n",
    "    clf = DecisionTreeClassifier(random_state=0, criterion='entropy', max_depth=3)\n",
    "    models.append(clf)\n",
    "    \n",
    "data_amount = X_train.shape[0]\n",
    "sample_size = data_amount * 0.7\n",
    "\n",
    "y_train\n",
    "for i in range(0,9):\n",
    "        models[i].fit(X_train.sample(int(sample_size)),y_train.sample(int(sample_size)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbd3d19c050dd71f190eafb081f44c6143cd12a6facd1212183781fccd0b1d56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
